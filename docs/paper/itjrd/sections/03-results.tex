\section{Results and Discussion}
\label{sec:results}

Testing was conducted based on the scenarios defined in the methodology. Results address space utilization, computation time scalability, algorithm variant performance, and visual validation.

\subsection{Experimental Setup}

Testing was conducted on a system with Intel Core i5-6440HQ @ 2.60GHz processor, 16 GB RAM, and Linux operating system. The application used Python 3.11 for the packing service and Go 1.21 for the backend API. Each scenario was executed five times to obtain mean values and standard deviations.

The container used throughout testing was a 40-foot High Cube type with internal dimensions of 12.032 $\times$ 2.352 $\times$ 2.698 meters (volume 76.35 m\textsuperscript{3}) and maximum load capacity of 26,460 kg. Four product types with varying dimensions were defined to simulate item heterogeneity: Euro Pallet (1200$\times$800$\times$144 mm), Large Crate (1000$\times$600$\times$500 mm), Medium Box (600$\times$400$\times$400 mm), and Small Box (400$\times$300$\times$200 mm). Each scenario uses a subset of these product types as specified in Table \ref{tab:scenarios}.

\subsection{Performance Results}

Table \ref{tab:results} presents testing results for all five scenarios using the baseline algorithm configuration (Bigger First strategy with stability checking enabled). Measured metrics include volume utilization, weight utilization, fill rate, and computation time.

\begin{table}[h]
	\centering
	\caption{Loading Algorithm Performance Testing Results}
	\label{tab:results}
	\small
	\begin{tabular}{lrrrrr}
		\toprule
		\textbf{Scenario} & \textbf{Items} & \textbf{Vol. Util. (\%)} & \textbf{Weight Util. (\%)} & \textbf{Fill Rate (\%)} & \textbf{Time (ms)} \\
		\midrule
		S1                & 50             & 6.29 $\pm$ 0.00          & 2.83 $\pm$ 0.00            & 100.00                  & 320 $\pm$ 6        \\
		S2                & 100            & 8.80 $\pm$ 0.00          & 4.16 $\pm$ 0.00            & 100.00                  & 1,684 $\pm$ 131    \\
		S3                & 150            & 24.83 $\pm$ 0.00         & 11.15 $\pm$ 0.00           & 100.00                  & 5,213 $\pm$ 169    \\
		S4                & 200            & 35.45 $\pm$ 0.00         & 16.25 $\pm$ 0.00           & 100.00                  & 10,826 $\pm$ 168   \\
		S5                & 300            & 55.26 $\pm$ 0.00         & 25.32 $\pm$ 0.00           & 100.00                  & 38,343 $\pm$ 1,209 \\
		\bottomrule
	\end{tabular}
\end{table}

The standard deviation of 0.00 for utilization metrics reflects the deterministic nature of the algorithm, where identical inputs produce identical placement results. Only computation time exhibits variance due to system-level factors such as process scheduling and memory allocation.

The algorithm successfully placed all items (100\% fill rate) across all scenarios, indicating that the 40-foot High Cube container capacity is adequate for the tested item configurations. The relatively low utilization values in scenarios S1 and S2 reflect the test design rather than algorithm inefficiency; these scenarios intentionally use fewer items than required to fill the container, allowing assessment of algorithm behavior across varying load levels. Volume utilization increases proportionally with item count, from 6.29\% in S1 to 55.26\% in S5. Weight utilization values consistently lower than volume utilization indicate that the configuration is volume-constrained rather than weight-constrained.

Figure \ref{fig:utilization} visualizes the comparison of volume and weight utilization for each scenario. Volume utilization consistently exceeds weight utilization with approximately a 2:1 ratio, confirming the volume-constrained characteristics of the test configuration.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{figures/utilization_comparison.pdf}
	\caption{Comparison of volume and weight utilization in each scenario}
	\label{fig:utilization}
\end{figure}

\subsection{Computation Time Analysis}

An important consideration in 3D-BPP evaluation is computation time scalability with increasing item counts. Table \ref{tab:scalability} presents detailed computation time statistics, including minimum, average, and maximum values for each scenario.

\begin{table}[h]
	\centering
	\caption{Computation Time Scalability Analysis}
	\label{tab:scalability}
	\small
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Scenario} & \textbf{Items} & \textbf{Min (ms)} & \textbf{Avg (ms)} & \textbf{Max (ms)} \\
		\midrule
		S1                & 50             & 311               & 320               & 325               \\
		S2                & 100            & 1,489             & 1,684             & 1,791             \\
		S3                & 150            & 5,012             & 5,213             & 5,391             \\
		S4                & 200            & 10,544            & 10,826            & 10,972            \\
		S5                & 300            & 36,334            & 38,343            & 39,288            \\
		\bottomrule
	\end{tabular}
\end{table}

Figure \ref{fig:scalability} illustrates the relationship between item count and computation time. Computation time exhibits quadratic growth ($O(n^2)$), consistent with heuristic-based bin packing algorithm characteristics \cite{Ma2025}. For each item placement, the algorithm evaluates potential collisions with all previously positioned items, resulting in quadratic complexity.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{figures/computation_time.pdf}
	\caption{Computation time scalability with respect to item count}
	\label{fig:scalability}
\end{figure}

Although computation time in scenario S5 (300 items) reaches an average of 38 seconds, this value remains acceptable for offline loading planning applications. In logistics operational contexts, loading planning is typically performed before physical loading commences, making wait times under one minute acceptable for operational requirements \cite{Tresca2022}.

\subsection{Algorithm Variant Comparison}

To assess the contribution of each algorithm component, comparative testing was performed with three configuration variants on scenario S3 (150 items). Table \ref{tab:variants} presents comparison results between the baseline configuration (Bigger First with Stability), a variant without stability checking, and a variant using the Smaller First strategy.

\begin{table}[h]
	\centering
	\caption{Algorithm Variant Comparison in Scenario S3 (150 items)}
	\label{tab:variants}
	\small
	\begin{tabular}{lrrrr}
		\toprule
		\textbf{Variant}            & \textbf{Vol. Util. (\%)} & \textbf{Fill Rate (\%)} & \textbf{Time (ms)} & \textbf{Items Packed} \\
		\midrule
		Bigger First + Stability    & 24.83                    & 100.00                  & 5,386              & 150                   \\
		Bigger First (No Stability) & 24.83                    & 100.00                  & 4,960              & 150                   \\
		Smaller First + Stability   & 17.37                    & 87.33                   & 32,886             & 131                   \\
		\bottomrule
	\end{tabular}
\end{table}

The comparison reveals that the Bigger First strategy substantially outperforms Smaller First, yielding 43\% relatively higher volume utilization (24.83\% vs. 17.37\%) and achieving complete placement compared to only 87.33\% fill rate. This confirms the heuristic principle that placing large items first leaves small gaps fillable by smaller items, whereas the reverse approach creates suboptimal fragmentation \cite{Ma2025}. The Smaller First variant also requires 6.1 times longer execution (32,886 ms vs. 5,386 ms) due to increased failed placement attempts when small items occupy spaces more suitable for large items.

Disabling stability checking saves only approximately 8\% computation time (4,960 ms vs. 5,386 ms) without affecting utilization results. This indicates that stability checking overhead is relatively small and worth retaining to ensure physical loading safety.

\subsection{Validation Results}

Visual examination through the implemented 3D visualization interface (Figure \ref{fig:visualization}) confirmed that all placements satisfy three validation criteria. No overlapping items were detected in any scenario; position coordinates and dimensions of each item showed no geometric intersections. All items remained within container boundaries without exceeding walls or floor limits. Stability requirements were met, with all elevated items having at least 75\% base area support, consistent with configured \texttt{support\_surface\_ratio} parameters.

The step playback feature enables verification of item placement sequence. Adjusting the step control from 1 to the total item count reveals that large items (Euro Pallet and Large Crate) are placed first, followed by smaller items filling remaining spaces. This pattern is consistent with the configured Bigger First strategy.

\subsection{Comparative Analysis}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=\textwidth]{figures/detailed_metrics.png}
	\caption{Performance metric summary: (a) volume utilization, (b) fill rate, (c) time scalability, (d) volume and weight utilization correlation}
	\label{fig:detailed}
\end{figure}

The developed system successfully processes up to 300 heterogeneous items with 100\% fill rate, achieves volume utilization up to 55.26\%, and completes calculations within 38 seconds for the largest scenario (Figure \ref{fig:detailed}). The system produces physically stable arrangements with minimum 75\% support and provides step-by-step visual guidance to assist operators in physical loading execution.

Comparison with existing literature indicates that the achieved volume utilization (55.26\% in the densest scenario) falls within expected ranges for heterogeneous cases with stability constraints. Table \ref{tab:literature} summarizes performance metrics from related studies for contextual comparison.

\begin{table}[h]
	\centering
	\caption{Comparison with Related Literature}
	\label{tab:literature}
	\small
	\begin{tabularx}{\textwidth}{lXll}
		\toprule
		\textbf{Study}                         & \textbf{Method}          & \textbf{Utilization/Fill Rate} & \textbf{Computation Time} \\
		\midrule
		Ananno \& Ribeiro \cite{Ananno2024}    & Multi-heuristic + GA     & 50--70\%                       & Varies by order           \\
		Ma et al. \cite{Ma2025}                & Block-building + GA + SA & 60--75\%                       & Not specified             \\
		Hoa et al. \cite{Hoa2024}              & GA + Wall-building       & Up to 91.67\% fill             & Not specified             \\
		Tresca et al. \cite{Tresca2022}        & MILP + Layer-building    & High quality                   & $<$30s per bin            \\
		Fontaine \& Minner \cite{Fontaine2023} & Branch-and-repair MILP   & Optimal for bin selection      & 30\% faster than baseline \\
		Zhao et al. \cite{Zhao2022}            & DRL + Stacking tree      & +10\% vs baseline              & Training required         \\
		\textbf{This research}                 & Heuristic (Bigger First) & 55.26\%                        & 38s (300 items)           \\
		\bottomrule
	\end{tabularx}
\end{table}

Ananno and Ribeiro \cite{Ananno2024} reported 50--70\% utilization for industrial cases with similar stability constraints (75\% minimum support area), while Ma et al. \cite{Ma2025} achieved 60--75\% on datasets with more homogeneous items. Hoa et al. \cite{Hoa2024} obtained higher fill rates (up to 91.67\%) for textile industry applications using genetic algorithms with wall-building heuristics, though their configuration involved different constraint priorities including purchase order sequencing; earlier work using simulated annealing achieved approximately 85\% fill rates with deadline-based prioritization \cite{Hoa2024}. The utilization difference in this research can be attributed to the high degree of dimensional heterogeneity in the test configuration, which presents greater packing challenges than homogeneous item sets. Additionally, metaheuristic approaches such as GA typically achieve higher utilization by exploring larger solution spaces at the cost of longer computation times. Direct comparison across studies is inherently limited due to variations in container types, item characteristics, and constraint specifications.

From a computational perspective, the quadratic time complexity observed aligns with findings by Tresca et al. \cite{Tresca2022}, who reported similar scaling behavior for greedy heuristics in container loading problems. Their matheuristic approach achieved configurations in under 30 seconds per bin on average, comparable to the performance observed in this research. Fontaine and Minner \cite{Fontaine2023} demonstrated that MILP-based approaches for e-commerce bin selection can achieve 30\% runtime reduction through branch-and-repair methods, though such exact methods are typically applied to smaller problem instances. The sub-minute computation times for 300 items compare favorably with metaheuristic approaches such as those by Zhao et al. \cite{Zhao2022}, which may require longer execution times for equivalent problem sizes but can yield marginally higher utilization through more exhaustive search. This trade-off between computation speed and solution quality supports the selection of heuristic methods for interactive planning applications where rapid feedback is prioritized over marginal utilization gains.

